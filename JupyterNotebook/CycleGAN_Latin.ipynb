{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于Cycle-GAN的字体风格模仿与生成 \n",
    "作者：ECUST wck，clf  \n",
    "导师：yfl  \n",
    "@ECUST-CS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#包引入\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置训练集目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置训练集与测试集目录\n",
    "\n",
    "dir = '/data/datasets/monet2photo'\n",
    "dir = 'F:/WorkSpace/Python-CV/CycleGAN-straightforward-master/data/datasets/monet2photo'\n",
    "dir = \"F:/WorkSpace/Python-CV/CycleGAN-straightforward-master/data_Latin\"\n",
    "\n",
    "train_paintings_dir = dir + '/trainA/'\n",
    "train_photos_dir = dir + '/trainB/'\n",
    "\n",
    "paintings_addr = [train_paintings_dir+i for i in os.listdir(train_paintings_dir)]\n",
    "photos_addr = [train_photos_dir+i for i in os.listdir(train_photos_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从系统目录读取并存入训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从系统目录中读取并将文件存在img[]链表中，作为训练集数据\n",
    "\n",
    "def create_train_sets(paintings_addr, photos_addr):\n",
    "    \n",
    "    X_train, Y_train = np.zeros((1072, 3, 128, 128), dtype=np.float32), np.zeros((6287, 3, 128, 128), dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(paintings_addr)):\n",
    "        temp_np = np.asarray(Image.open(paintings_addr[i]).resize((128, 128), Image.ANTIALIAS))  #resizing the image to 128x128\n",
    "        X_train[i] = temp_np.transpose(2, 0, 1)\n",
    "        X_train[i] /= 255\n",
    "        X_train[i] = X_train[i] * 2 -  1\n",
    "        \n",
    "    for i in range(len(photos_addr)):\n",
    "        temp_np = np.asarray(Image.open(photos_addr[i]).resize((128, 128), Image.ANTIALIAS))\n",
    "        Y_train[i] = temp_np.transpose(2, 0, 1)\n",
    "        Y_train[i] /= 255\n",
    "        Y_train[i] = Y_train[i] * 2 -  1\n",
    "    \n",
    "    return X_train, Y_train\n",
    "X_train, Y_train = create_train_sets(paintings_addr, photos_addr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （可选）保存读取的数据集\n",
    "> 方便下次读取，不需要再加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train', X_train)\n",
    "np.save('Y_train', Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (可选）加载保存的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "Y_train = np.load('Y_train.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 转换为Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " X_tensor = torch.from_numpy(X_train)                #Creating Tensors which will later be wrapped into variables\n",
    "Y_tensor = torch.from_numpy(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全局判别器\n",
    "> 采用128*128的全图进行判别，输出结果为Di/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator_nonpatch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator_nonpatch, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(512, 512, kernel_size=6, stride=1)\n",
    "        \n",
    "        self.head = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = Fn.leaky_relu(self.conv1(input), negative_slope=0.2)\n",
    "        x = Fn.leaky_relu(self.bn2(self.conv2(x)), negative_slope=0.2)\n",
    "        x = Fn.leaky_relu(self.bn3(self.conv3(x)), negative_slope=0.2)\n",
    "        x = Fn.leaky_relu(self.bn4(self.conv4(x)), negative_slope=0.2)\n",
    "        x = Fn.leaky_relu(self.conv5(x), negative_slope=0.2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return Fn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分区判别器 \n",
    "> 采用70*70的分区作为PatchGAN判别区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=4, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(256, 512, kernel_size=4, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(512, 512, kernel_size=2, stride=1)\n",
    "        \n",
    "        self.head = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = Fn.leaky_relu(self.conv1(input), negative_slope=0.2)\n",
    "        x = Fn.leaky_relu(self.bn2(self.conv2(x)), negative_slope=0.2)\n",
    "        x = Fn.leaky_relu(self.bn3(self.conv3(x)), negative_slope=0.2)\n",
    "        x = Fn.leaky_relu(self.bn4(self.conv4(x)), negative_slope=0.2)\n",
    "        x = Fn.leaky_relu(self.conv5(x), negative_slope=0.2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return Fn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(nn.Module):         #padding concerns: reflection? What exactly is the concept behind convTranspose?\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        \n",
    "        #c7s1-32\n",
    "        self.r1 = nn.ReflectionPad2d(3)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        #d64\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        #d128\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #R128\n",
    "        self.r4 = nn.ReflectionPad2d(1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.r5 = nn.ReflectionPad2d(1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #R128\n",
    "        self.r6 = nn.ReflectionPad2d(1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.r7 = nn.ReflectionPad2d(1)\n",
    "        self.conv7 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #R128\n",
    "        self.r8 = nn.ReflectionPad2d(1)\n",
    "        self.conv8 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.r9 = nn.ReflectionPad2d(1)\n",
    "        self.conv9 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn9 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #R128\n",
    "        self.r10 = nn.ReflectionPad2d(1)\n",
    "        self.conv10 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn10 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.r11 = nn.ReflectionPad2d(1)\n",
    "        self.conv11 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn11 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #R128\n",
    "        self.r12 = nn.ReflectionPad2d(1)\n",
    "        self.conv12 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn12 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.r13 = nn.ReflectionPad2d(1)\n",
    "        self.conv13 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn13 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #R128\n",
    "        self.r14 = nn.ReflectionPad2d(1)\n",
    "        self.conv14 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn14 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.r15 = nn.ReflectionPad2d(1)\n",
    "        self.conv15 = nn.Conv2d(128, 128, kernel_size=3)\n",
    "        self.bn15 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        #u64\n",
    "        self.uconv16 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.bn16 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        #u32\n",
    "        self.uconv17 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.bn17 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        #c7s1-3\n",
    "        self.r18 = nn.ReflectionPad2d(3)\n",
    "        self.conv18 = nn.Conv2d(32, 3, kernel_size=7, stride=1)\n",
    "        self.bn18 = nn.BatchNorm2d(3)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        #c7s1-32\n",
    "        x = Fn.leaky_relu(self.bn1(self.conv1(self.r1(input))), negative_slope=0.2)\n",
    "        \n",
    "        #d64\n",
    "        x = Fn.leaky_relu(self.bn2(self.conv2(x)), negative_slope=0.2)\n",
    "        \n",
    "        #d128\n",
    "        x = Fn.leaky_relu(self.bn3(self.conv3(x)), negative_slope=0.2)\n",
    "        \n",
    "        #R128\n",
    "        x1 = Fn.leaky_relu(self.bn4(self.conv4(self.r4(x))), negative_slope=0.2)\n",
    "        x1 = Fn.leaky_relu(self.bn5(self.conv5(self.r5(x1))), negative_slope=0.2)\n",
    "        \n",
    "        x = x + x1\n",
    "        \n",
    "        #R128\n",
    "        x1 = Fn.leaky_relu(self.bn6(self.conv6(self.r6(x))), negative_slope=0.2)\n",
    "        x1 = Fn.leaky_relu(self.bn7(self.conv7(self.r7(x1))), negative_slope=0.2)\n",
    "        \n",
    "        x = x + x1\n",
    "        \n",
    "        #R128\n",
    "        x1 = Fn.leaky_relu(self.bn8(self.conv8(self.r8(x))), negative_slope=0.2)\n",
    "        x1 = Fn.leaky_relu(self.bn9(self.conv9(self.r9(x1))), negative_slope=0.2)\n",
    "        \n",
    "        x = x + x1\n",
    "        \n",
    "        #R128\n",
    "        x1 = Fn.leaky_relu(self.bn10(self.conv10(self.r10(x))), negative_slope=0.2)\n",
    "        x1 = Fn.leaky_relu(self.bn11(self.conv11(self.r11(x1))), negative_slope=0.2)\n",
    "        \n",
    "        x = x + x1\n",
    "       \n",
    "        #R128\n",
    "        x1 = Fn.leaky_relu(self.bn12(self.conv12(self.r12(x))), negative_slope=0.2)\n",
    "        x1 = Fn.leaky_relu(self.bn13(self.conv13(self.r13(x1))), negative_slope=0.2)\n",
    "        \n",
    "        x = x + x1\n",
    "        \n",
    "        #R128\n",
    "        x1 = Fn.leaky_relu(self.bn14(self.conv14(self.r14(x))), negative_slope=0.2)\n",
    "        x1 = Fn.leaky_relu(self.bn15(self.conv15(self.r15(x1))), negative_slope=0.2)\n",
    "        \n",
    "        x = x + x1\n",
    "        \n",
    "        #u64\n",
    "        x = Fn.leaky_relu(self.bn16(self.uconv16(x)), negative_slope=0.2)\n",
    "        \n",
    "        #u32\n",
    "        x = Fn.leaky_relu(self.bn17(self.uconv17(x)), negative_slope=0.2)\n",
    "        \n",
    "        #c7s1-3\n",
    "        x = Fn.leaky_relu(self.bn18(self.conv18(self.r18(x))), negative_slope=0.2)\n",
    "        \n",
    "        return Fn.tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 权重函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 裁剪函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_through_discriminator(discriminator, image):\n",
    "    score, k = 0, Variable(torch.zeros(1)).type(dtype)\n",
    "    xp, yp = 0, 0\n",
    "    x, y = 70, 70\n",
    "    offset = 25\n",
    "    \n",
    "    while x < 128:\n",
    "        while y < 128:\n",
    "            k += 1\n",
    "            score += discriminator(image[:, :, xp:x, yp:y])\n",
    "            yp += offset\n",
    "            y += offset\n",
    "            \n",
    "        xp += offset\n",
    "        x += offset\n",
    "        \n",
    "    return score / k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化D和G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ed633850556d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    \n",
    "G = generator().type(dtype)\n",
    "F = generator().type(dtype)\n",
    "\n",
    "Dg = discriminator().type(dtype)\n",
    "Df = discriminator().type(dtype)\n",
    "Dgnp = discriminator_nonpatch().type(dtype)\n",
    "Dfnp = discriminator_nonpatch().type(dtype)\n",
    "\n",
    "G.apply(weights_init)\n",
    "F.apply(weights_init)\n",
    "Dg.apply(weights_init)\n",
    "Df.apply(weights_init)\n",
    "\n",
    "G_optim = optim.Adam(G.parameters(), lr=0.0002)    #Learning rates directly borrowed from the paper\n",
    "F_optim = optim.Adam(F.parameters(), lr=0.0002)\n",
    "\n",
    "Dg_optim = optim.Adam(Dg.parameters(), lr=0.0001)\n",
    "Df_optim = optim.Adam(Df.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 1\n",
    "\n",
    "G.train()\n",
    "F.train()\n",
    "Dg.train()\n",
    "Df.train()\n",
    "\n",
    "k = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print ('Epoch number: {0}'.format(epoch))\n",
    "    \n",
    "    for batch in range(X_tensor.size(0) // batch_size):\n",
    "        if batch % 100 == 0:\n",
    "            print( '**Batch number: {0}**'.format(batch))\n",
    "        \n",
    "        painting_real = X_tensor[batch * batch_size: (batch + 1) * batch_size]\n",
    "        if k!= 6286:\n",
    "            photo_real = Y_tensor[k % 6287: (k + 1) % 6287]       \n",
    "        else:\n",
    "            photo_real = Y_tensor[6286] \n",
    "            photo_real = photo_real[np.newaxis, ...]\n",
    "        k += 1\n",
    "        \n",
    "        painting_real = Variable(painting_real).type(dtype)\n",
    "        photo_real = Variable(photo_real).type(dtype)\n",
    "        \n",
    "        #Train GAN G\n",
    "        \n",
    "        #Train Dg\n",
    "        photo_fake = G(painting_real)\n",
    "        \n",
    "        scores_real = pass_through_discriminator(Dg, photo_real)\n",
    "        scores_real_np = Dgnp(photo_real)\n",
    "        scores_fake = pass_through_discriminator(Dg, photo_fake)\n",
    "        scores_fake_np = Dgnp(photo_fake)\n",
    "        \n",
    "        label_fake = Variable(torch.zeros(batch_size)).type(dtype)\n",
    "        label_real = Variable(torch.ones(batch_size)).type(dtype)\n",
    "        \n",
    "        scores_real = (0.8 * scores_real + 0.2 * scores_real_np) \n",
    "        scores_fake = (0.8 * scores_fake + 0.2 * scores_fake_np) \n",
    "        \n",
    "        loss1 = torch.mean((scores_real - label_real)**2)\n",
    "        loss2 = torch.mean((scores_fake - label_fake)**2)\n",
    "        \n",
    "        Dg_optim.zero_grad()\n",
    "        \n",
    "        loss_dg = (loss1 + loss2)\n",
    "        if batch % 100 == 0:\n",
    "            print ('Discriminator G loss: {0}'.format(loss_dg.item()) ) \n",
    "        loss_dg.backward()\n",
    "        \n",
    "        Dg_optim.step()\n",
    "\n",
    "        #Train G\n",
    "        photo_fake = G(painting_real)\n",
    "        \n",
    "        scores_fake = pass_through_discriminator(Dg, photo_fake)\n",
    "        loss_g = torch.mean((scores_fake - label_real)**2) + 10 * torch.mean(torch.abs(G(F(photo_real)) - photo_real))\n",
    "        if batch % 100 == 0:\n",
    "            print ('Generator G loss: {0}'.format(loss_g.item()))\n",
    "        \n",
    "        G_optim.zero_grad()\n",
    "        loss_g.backward()\n",
    "        G_optim.step()\n",
    "        \n",
    "        #Train GAN F\n",
    "        \n",
    "        painting_fake = F(photo_real)\n",
    "        \n",
    "        scores_real = pass_through_discriminator(Df, painting_real)\n",
    "        scores_real_np = Dfnp(painting_real)\n",
    "        scores_fake = pass_through_discriminator(Df, painting_fake)\n",
    "        scores_fake_np = Dfnp(painting_fake)\n",
    "        \n",
    "        scores_real = (0.8 * scores_real + 0.2 * scores_real_np)\n",
    "        scores_fake = (0.8 * scores_fake + 0.2 * scores_fake_np)\n",
    "        \n",
    "        loss1 = torch.mean((scores_real - label_real)**2)\n",
    "        loss2 = torch.mean((scores_fake - label_fake)**2)\n",
    "        \n",
    "        Df_optim.zero_grad()\n",
    "        \n",
    "        loss_df = (loss1 + loss2)\n",
    "        if batch % 100 == 0:\n",
    "            print ('Discriminator F loss: {0}'.format(loss_df.item()))\n",
    "        loss_df.backward()\n",
    "        \n",
    "        Df_optim.step()\n",
    "        \n",
    "        #Train F\n",
    "        \n",
    "        painting_fake = F(photo_real)\n",
    "        \n",
    "        scores_fake = pass_through_discriminator(Df, painting_fake)\n",
    "        loss_f = torch.mean((scores_fake - label_real)**2) + 10 * torch.mean(torch.abs(F(G(painting_real)) - painting_real))\n",
    "        if batch % 100 == 0:\n",
    "            print ('Generator F loss: {0}'.format(loss_f.item()))\n",
    "        \n",
    "        F_optim.zero_grad()\n",
    "        loss_f.backward()\n",
    "        F_optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple function for unpreprocessing and displaying results\n",
    "\n",
    "def test_image(img_addr):\n",
    "    img = Image.open(img_addr)\n",
    "    img_np = np.zeros((1, 3, 128, 128), dtype=np.float32)\n",
    "    temp_np = np.asarray(img.resize((128, 128), Image.ANTIALIAS))\n",
    "    plt.imshow(temp_np)\n",
    "    \n",
    "    img_np[0] = temp_np.transpose(2, 0, 1)\n",
    "    \n",
    "    img_np /= 255\n",
    "    img_np = img_np * 2 - 1\n",
    "    img_tensor = torch.from_numpy(img_np)\n",
    "    img_var = Variable(img_tensor).type(dtype)\n",
    "    \n",
    "    photo_var = G(img_var)\n",
    "    photo = photo_var.data.cpu().numpy()\n",
    "    photo = photo[0].transpose(1, 2, 0)\n",
    "    photo = (photo + 1)/2\n",
    "    plt.figure()\n",
    "    plt.imshow(photo)\n",
    "    \n",
    "    paint_var = F(photo_var)\n",
    "    paint = paint_var.data.cpu().numpy()\n",
    "    paint = paint[0].transpose(1, 2, 0)\n",
    "    paint = (paint + 1)/2\n",
    "    plt.figure()\n",
    "    plt.imshow(paint)\n",
    "test_image(paintings_addr[27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo2monet(photo_addr):\n",
    "    img = Image.open(photo_addr)\n",
    "    img_np = np.zeros((1, 3, 128, 128), dtype=np.float32)\n",
    "    temp_np = np.asarray(img.resize((128, 128), Image.ANTIALIAS))\n",
    "    plt.imshow(temp_np)\n",
    "    \n",
    "    img_np[0] = temp_np.transpose(2, 0, 1)\n",
    "    \n",
    "    img_np /= 255\n",
    "    img_np = img_np * 2 - 1\n",
    "    img_tensor = torch.from_numpy(img_np)\n",
    "    img_var = Variable(img_tensor).type(dtype)\n",
    "    \n",
    "    paint_var = F(img_var)\n",
    "    paint = paint_var.data.cpu().numpy()\n",
    "    paint = paint[0].transpose(1, 2, 0)\n",
    "    paint = (paint + 1)/2\n",
    "    plt.figure()\n",
    "    plt.imshow(paint)\n",
    "photo2monet(photos_addr[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## （可选）模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G,\"trainG.pkl\")\n",
    "torch.save(F,\"trainF.pkl\")\n",
    "torch.save(Df,\"trainDf.pkl\")\n",
    "torch.save(Dg,\"trainDg.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaPython3",
   "language": "python",
   "name": "anapython3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
